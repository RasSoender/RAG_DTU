{
    "course title": "34759 Perception for Autonomous Systems",
    "Danish title": "Perception for Autonome Systemer",
    "Language of instruction": "English",
    "Point( ECTS )": "10",
    "Course type": "MSc\nProgramme specific course (MSc), Autonomous Systems\nTechnological specialization course (MSc), Autonomous Systems",
    "Schedule": "Autumn E1 (Mon 8-12, Thurs 13-17)",
    "Location": "Campus Lyngby",
    "Scope and form": "Lectures, exercises, group work and homework.",
    "Duration of Course": "13 weeks",
    "Date of examination": "E1B",
    "Type of assessment": "Written examination and experiments\nApproval of report is mandatory for taking the exam. The written exam is multiple-choice. The report and the exam will be evaluated together. Re-exam can be written or oral exam only (when the report is approved).",
    "Exam duration": "Written exam: 4 hours",
    "Aid": "All Aid - no access to the internet :\nWritten exam with all aids and closed internet.",
    "Evaluation": "7 step scale , internal examiner",
    "Not applicable together with": "31392",
    "Academic prerequisites": "3475831391 , Knowledge of Python programming is a prerequisite.",
    "Responsible": "Lazaros Nalpantidis , Lyngby Campus, Building 326 , lanalpa@dtu.dk",
    "Course co-responsible": "Evangelos Boukas , Lyngby Campus, Building 326 , evanb@dtu.dk",
    "Department": "34 Department of Electrical and Photonics Engineering",
    "Registration Sign up": "At the Studyplanner",
    "General course objectives": "General course objectives\nThe course familiarizes participants with the theory and practical applications of perception for autonomous systems. The aim is to enable students to transform sensory input from a variety of imaging and 3D sensors into more abstract descriptions of the observed scene. Thus, such techniques will allow autonomous systems to perceive their environment and act within it or interact with it. The course will provide both the mathematical descriptions and programming tools to implement such perception techniques.\nFinally, the aim is to enable the participants to use the taught concepts and tools to further develop either embodied (e.g. robotic) or intangible (e.g. software agent) autonomous systems.",
    "Learning objectives": "A student who has met the objectives of the course will be able to:\nDescribe the steps that lead to 3D reconstruction using multiple views.\nDefine commonly used image feature extraction and matching techniques,.\nDiscuss characteristics of various ranging sensors and techniques.\nApply software tools to process 3D point clouds.\nCombine visual and 3D sensory input with state estimation techniques.\nDescribe the differences between classical and learning-based object/scene classification techniques.\nDescribe the different steps in visual odometry and explain the operation of the related algorithms.\nCombine the taught material to propose and describe possible implementations of further perception applications.",
    "Content": "Multiple View Geometry, Image Feature Detection and Description, Ranging, 3D Cloud Processing, Object Pose Estimation, State Estimation, Classification, Visual Odometry, SLAM, Object Detection.\nThe exercise part consists of introductory exercises and a project solved in teams.",
    "Last updated": "02. maj, 2024"
}