{
    "course title": "02428 Dynamic Optimization",
    "Danish title": "Dynamisk Optimering",
    "Language of instruction": "English",
    "Point( ECTS )": "5",
    "Course type": "MSc\nOffered as a single course\nProgramme specific course (MSc), Mathematical Modelling and Computation",
    "Schedule": "Autumn E4A (Tues 13-17)",
    "Location": "Campus Lyngby",
    "Scope and form": "Lectures. Exercises. methods",
    "Duration of Course": "13 weeks",
    "Date of examination": "E4A",
    "Type of assessment": "Oral examination",
    "Exam duration": "20 minutes",
    "Aid": "All Aids - with access to the internet",
    "Evaluation": "7 step scale , internal examiner",
    "Not applicable together with": "42111\nThere is significant overlap with the cancelled 42111 Static and Dynamic Optimization",
    "Academic prerequisites": "01617 , Dynamic systems (e.g. 01617). Optimization including constrained optimization and Lagrange multipliers (e.g. 02612). Some exposure to partial differential equations will be helpful (e.g. 01418). Elementary probability is needed and exposure to Markov chains is helpful (e.g. 02407).",
    "Participants restrictions": "Maximum: 40",
    "Responsible": "Uffe Høgsbro Thygesen , Lyngby Campus, Building 303B, Ph. (+45) 4525 3060 , uhth@dtu.dk",
    "Department": "01 Department of Applied Mathematics and Computer Science",
    "Registration Sign up": "At the Studyplanner",
    "Green challenge participation": "This course gives the student an opportunity to prepare a project that may participate in DTU's Study Conference on sustainability, climate technology, and the environment (GRØN DYST). More information http://www.groendyst.dtu.dk/english",
    "General course objectives": "General course objectives\nThe course elucidates the common themes and techniques in dynamic optimization. Starting with classical examples of dynamic optimization from mathematical physics (such as shortest path problems and minimum energy problems), we develop calculus of variations and its generalisation to optimal control using Hamiltonian formalism. We explore dynamic programming (in the sense of Bellman) and how it applies to a variety of problems, discrete and continuous, as well as deterministic and stochastic. We examine dynamic games, both two-player games and mean-field approximations to many-player games. The theory is illustrated with simple canonical examples from physics and from decision and control. We cover simple numerical methods.",
    "Learning objectives": "A student who has met the objectives of the course will be able to:\nTo apply the Euler-Lagrange equation to identify stationary points for integral functionals\nTo apply the Maximum Principle of Pontryagin to identify optimal controls.\nTo pose and solve the Dynamic Programming equation for optimal control of differential equations.\nTo compute linearized feedback strategies which apply near optimal equilibria and trajectories.\nTo pose and solve the Dynamic Programming equation for Markov Decision Problems and optimization problems on graphs\nTo analyze two-player and mean-field dynamic games\nTo analyse dynamic optimization problems both theoretically and numerically\nTo give examples of dynamic optimization problems in physics, decision, and control",
    "Content": "Optimization over function spaces; calculus of variations. Pontryagin’s maximum principle; Hamiltonian formalism. Dynamic programming on graphs. Markov Decision Problems. The Hamilton-Jacobi-Bellman equation for optimal control. Dynamic games; mean-field games. Numerical methods for optimal control.",
    "Course literature": "Excerpts from textbooks: Kamien & Schwarts (1999) Dynamic Optimization. Liberzon (2012) Calculus of variations and optimal control. Notes.",
    "Last updated": "02. maj, 2024"
}